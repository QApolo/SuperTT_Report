\chapter{Marco teórico}
Con el desarrollo del sistema producto del presente Trabajo Terminal se involucran ciertos conceptos provenientes en su mayoría de ramas de ciencias de la computación y en general en alusión a la Inteligencia Artificial, por lo que es conveniente dar contexto sobre los elementos necesarios para su desarrollo.

\section{Análisis de Imágenes}\label{sec:imAnalysis}
		
		Una imagen puede definirse como una función bidimensional. $f(x,y)$, donde $x$ y $y$ son coordenadas espaciales (plano) y la amplitud de $f$ en cualquier par de coordenadas $(x,y)$ es llamada \textit{intensity} o \textit{gray level} (nivel de grises) de la imagen en ese punto.
		\\
		Cuando $x, y$ y los valores de amplitud de $f$ son todas cantidades discretas finitas, la imagen se denomina imagen digital. El campo de análisis de imagen se refiere a procesar imagenes por medio de una computadora digital. Una imagen digital está compuesta por número de elementos finitos, de los cuales cada uno tiene una posición particular y valor. Estos elementos son referidos como \textbf{picture elements, image elements, pels} y \textbf{pixels}. Pixel es el término más ampliamente usado para denotar los elementos de una imagen digital.
		\\
		
        El análisis de imágenes comprende un conjunto de operaciones sobre una o varias imágenes con el propósito de obtener una imagen con mayor realce o para extraer características útiles, es un tipo de dispensación de señales en el que la entrada es una imagen y la salida puede ser otra imagen o características asociadas a la imagen, algunos de los pasos generales se describen a continuación:
        
        \subsection{Preprocesamiento}
            Preprocesamiento es un nombre común para operaciones con imágenes al más bajo nivel de abstracción. Tanto entrada como salida son imágenes de intensidad. Estas imágenes tienen el mismo tipo de datos que la original, con una imagen de intensidad usualmente representada por una matriz de valores de función de imagen (Brillo) El objetivo de preprocesar es la mejora de los datos de la imagen que borre distorciones o realce características importantes para procesamiento posterior, incluso las transformaciones geométricas de las imagenes e.g (rotación, escalamiento y traslación) son también clasificadas como métodos de preprocesamiento, ya que técnicas similares son utilizadas \cite{imgAnalySeg}.
               
                
        \subsection{Realce de la imagen}
            El objetivo principal de realce de imagen es también procesar una imagen dada tal que el resultado sea mas ajustable que la imagen original para aplicaciones específicas. Por ejemplo para la remoción de ruido.
            \\\\%\bigskip
            Acentúa o afina características de la imagen como ejes, límites o contraste para hacer un despliegue gráfico mas útil para el análisis.
            \\\\%%\bigskip
            El realce no incrementa o decrementa el contenido de la información inherente de los datos pero sí incrementa el rango dinámico de las características elegidas de tal modo que puedan ser detectadas fácilmente.
            \\\\%\bigskip
            Proveé \'mejor\' entrada para otras técnicas avanzadas de procesamiento automatizadas de imágenes.
			\\\\%\bigskip
			Los enfoques de realce de imagen se dividen en categorías amplias: métodos de dominio espacial y métodos de dominio de frecuencia. El término \textit{dominio espacial} se refiere al plano mismo de la imagen y las aproximaciones en esta categoría son basadas en manipulación directa en una imagen. Técnicas de procesamiento de  \textit{dominio de frecuencia} están basadas en modificar la transformada de Fourier de una imagen.
			
			El término \textit{dominio espacial} se refiere al agregado de pixeles que componen una imagen. Los métodos de dominio espacial son procesos que operan directamente en estos pixeles. Los procesos de dominio espacial serán denotados por la expresión
			\begin{equation}
				g(x,y) = T[f(x,y)]
			\end{equation}
			donde $f(x,y)$ es la imagen de entrada, $g(x,y)$ es la imagen procesada y $T$ es un operador sobre $f$, definido sobre alguna vecindad de $(x,y)$. Además, $T$ puede operar sobre un conjunto de imágenes de entrada, como llevar a cabo la suma \texttt{pixel-by-pixel} de $K$ imágenes para reducción de ruido.
			\\\\%bigskip
			La principal aproximación para definir una vecindad de un punto $(x,y)$ es usar una área de una sub-imagen cuadrada o rectangular centrada en $(x,y)$, como se muestra en %ref
			
			El centro de la subimagen es movido de pixel a pixel iniciando por ejemplo en la esquina superior izquierda. El operador $T$ es aplicado en cada posición $(x,y)$ para producir la salida $g$ en esa posición. El proceso utiliza solo los pixeles en el área de la imagen expandida por la vecindad. A pesar de que otras vecindades le dan forma, como aproximaciones a un círculo son usadas en ocasiones, arreglos cuadrados y rectangulares son por mucho los más predominantes por la facilidad de implementación.
			\\\\%bigskip
			La forma mas simple de $T$ es cuando la vecindad es de tamaño $1x1$ (un solo pixel). En este caso, $g$ depende solo del valor de $f$ en $(x,y)$ y $T$ se convierte en una \textit{función de transformación a nivel de grises} (también llamada \textit{intensity o mapeo}) de la forma
			\begin{equation}
			\label{eq:str_eq}
				s = T(r)
			\end{equation}
			donde por simplicidad de notación, $r$ y $s$ son variables denotando respectivamente el nivel de gris de $f(x,y)$ y $g(x,y)$ en cualquier punto $(x,y)$. Por ejemplo, si $T(r)$ tiene la forma mostrada en \ref{fig:contrast__enhanc}(a), el efecto de esta transformación sería producir una imagen de mas alto contraste que la original al oscurecer los niveles debajo de $m$ y darle brillo a los niveles arriba de $m$ en la imagen original. En esta técnica conocida como contrast stretching, los valores de $r$ por debajo de $m$ son comprimidos por la función de transformación en un rango estrecho de $s$ hacia el negro. El efecto opuesto da lugar para valores de $r$ por encima de $m$. En el caso limitante mostrado en \ref{fig:contrast__enhanc}(b), $T(r)$ produce una imagen two-level (binaria). Un mapeo de esta forma es llamado una función de \textit{thresholding}.
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\textwidth]{capitulo2/images/glev_trans.png}
				\caption{Transformación de nivel de grises para realce de contraste.}
				\label{fig:contrast__enhanc}
			\end{figure}
		\subsubsection{Transformaciones a nivel de grises básicas}
		Las transformaciones a nivel de grises son las más básicas en el proceso de realce de imágenes. Los valores de los pixeles antes y después de ser procesados se denotan por $r$ y $s$ respectivamente. Como se mencionó ateriormente, estos valores son relacionados por \ref{eq:str_eq}, como se trabaja con cantidades digitales, los valores de las funciones de transformación típicamente son almacenadas en un arreglo unidimensional y los mapeos de $r$ y $s$ son implementados via por búsquedas de tabla (lookup tables). Para un entorno de 8 bits, una tabla lookup que contiene los valores de $T$ tendrá 256 entradas.
		\\\\
		Como introducción a las transformaciones a nivel de grises, considera la figura \ref{fig:inp_gray_lev} la cual muestra tres tipos básicos de funciones usadas frecuentemente para realce de imágenes: lineal (transformaciones negative e identity), logarítmicas (transformaciones log e inverse-log) y power-law (transformaciones de potencia $n$th y raíz $n$th). La función identidad es el caso trivial en el cual las intensidades de salida son idénticas a la intensidades de entrada.
		
		\subsubsection{Negativos de Imagen}
		El negativo de una imagen con niveles de gris en el rango $[0, L-1]$ es obtenido al usar la transformación negativa mostrada en \ref{fig:inp_gray_lev}, la cual es dado por la expresión
		\begin{equation}
			s = L - 1 - r 
		\end{equation}
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.7\textwidth]{capitulo2/images/input_gray_level.png}
			\caption{Algunas transformaciones básicas a nivel de grises usadas para realce de imagen.}
			\label{fig:inp_gray_lev}
		\end{figure}
	      Invertir los niveles de intensidad de una imagen en esta formar produce el equivalente del negativo de fotografía. Este tipo de procesamiento es particularmente ajustado para el realce de detalles de blanco y negro embebidos en regiones oscuras de una imagen, especialmente cuando las áreas negras dominan en tamaño. 
		\subsubsection{Transformaciones Log}
		
		La forma general de la transformación log que se muestra en la figura \ref{fig:inp_gray_lev} es
		\begin{equation}
			s = clog(1 + r)
		\end{equation}
		donde $c$ es una constante y se asume que $r\geq0$. La forma de la curva log en \ref{fig:inp_gray_lev} muestra que esta transformación mapea un rango estrecho de valores con bajos niveles de gris en la imagen de entrada a un rango más amplio de niveles  de salida. Lo opuesto es verdadero de valores más altos de niveles de entrada. Este tipo de transformaciones se usa para expandir los valores de pixeles oscuros en una imagen mientras se comprimen los valores de nivel más altos. Lo opuesto es verdadero de la transformación inversa de log.
		
		Cualquier curva que tiene la forma general de funciones log mostradas en \ref{fig:inp_gray_lev} completaría esta expansión/compresión de niveles de gris de una imagen. Las transformaciones log tienen la importante característica de que comprime el rango dinámico de imágenes con grandes variaciones en valores de pixeles. Una clásica ilustración de una aplicación en la cual los valores de pixel tienen un gran rango dinámico es el espectro de Fourier, no es inusual encontrar valores de espectro entre $0$ y $10^6$ o más grandes.
		
		\subsubsection{Transformaciones Power-Law}
		Las transformaciones power-law tienen la forma básica
		\begin{equation}\label{eq:power_trans}
			s = cr^\gamma
		\end{equation}
		donde $c$ y $\gamma$ son constantes positivas. En ocasiones \ref{eq:power_trans} se escribe como $c(r+\epsilon)^\gamma$	para considerar una compensación (esto es, una salida medible cuando la entrada es cero). Sin embargo, las compensaciones típicamente son un problema de calibración y como resultado se ignoran normalmente en la ecuación \ref{eq:power_trans}. Las gráficas de $r$ vs $s$ para distintos valores de $\gamma$ se muestran en
		
		
        \subsection{Segmentación de la imagen}
            El término segmentación utilizada en el contexto de análisis de imágenes se refiere a la partición de una imagen en un conjunto de regiones que la cubren. El objetivo en muchas de las tareas es que para las regiones se representen áreas significativas de la imagen, como áreas urbanas, fronteras o bosques de una imagen satelital. En otras tareas de análisis, las regiones pueden ser conjuntos de bordes de pixeles agrupados en estructuras como segmentos de líneas y segmentos de arcos circulares en imágenes de objetos industriales en 3D. Las regiones pueden también estar definidas como grupos de pixeles teniendo ambos un borde y una forma particular como un circulo o una elipse or polígono. Cuando las regiones de interés no cubren la imagen completa, aún se requiere el proceso de segmentación en regiones de y de fondo para ignorarse. 
            \cite{imgAnalySeg}
            %REF courses.cs.washington.edu/courses/cse576/book/ch10.pdf
            \begin{figure}[H]
                \centering
                \includegraphics[width=0.7\textwidth]{capitulo2/images/segmentation.PNG}
                \caption{Imagen con bloques (Izquierda) y conjunto de segmentos de linea extraídos (Derecha).}
                \label{fig:segmentacion}
            \end{figure}
  
        
        
        %\subsection{Extracción de características}
            
            %http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.375.6848&rep=rep1&type=pdf
        %\subsection{Clasificación e interpretación}
            %http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.375.6848&rep=rep1&type=pdf


\newpage
\section{Deep Learning}
	
El aprendizaje profundo o \textit{deep learning} es una rama del aprendizaje automático (\textit{machine learning} en inglés) que intenta modelar abstracciones de alto nivel a través de complejas arquitecturas computacionales que admiten transformaciones no lineales. El deep learning es la evolución de las ya conocidas redes neuronales las cuales experimentaban problemas de desvanecimiento del gradiente si se usaban demasiadas capas. Con las nuevas técnicas propuestas en el deep learning se logro evitar este problema y así, poder entrenar arquitecturas de millones de parámetros. \\

El perceptrón multicapa (MLP) es el modelo más básico y aún así uno de los más útiles en el campo de las redes neuronales. Su principal objetivo es tratar de aproximar una función $f^{*}$. En el caso del \textit{aprendizaje supervisado}, la función $f^{*}$ toma la forma $y^{*} = f^{*}(x)$ de donde x es un parámetro de entrada que puede ser desde un simple número hasta un tensor y $y^{*}$ es la salida de la función. Entonces, una red neuronal que quiera aproximar $f^{*}$ definirá una función de mapeo de la forma $y = f(x,\theta)$ y aprenderá los parámetros $\theta$ (usualmente conocidos como $W$ y $b$) que dan como resultado la mejor aproximación de tal forma que $y \approx y^{*}$. \\

Las redes neuronales profundas son llamadas redes porque pueden representarse mediante la composición de varias funciones de mapeo. Es decir, un MLP que quiera aproximar una función puede expresarse como $y^{n} = f^{n}(y^{n-1}, \theta^{n})$ con $y^{1} = f^{1}(x, \theta^{1})$ y $n$ siendo la profundidad de la red.

	\subsection{Gráfos computacionales}
	Para describir con formalidad a las redes neuronales es preciso utilizar una notación que pueda ser expresada a través de gráfos. Según \cite{deeplearningbook} se puede indicar cada nodo del gráfo como una variable que puede ser un tensor para no perder generalidad. 
	
	Para terminar con la definición de estos gráfos, es necesario introducir el concepto de operación, la cual simplemente es una función entre dos o mas nodos del gráfo. Sin perder generalidad, se dice que una operación retorna únicamente una variable, es decir, un solo nodo.
	
	En la Figura \ref{fig:grafo-computacional} se puede ver un ejemplo de un perceptrón de una sola capa que es representado mediante un gráfo computacional. Gracias a esta definición, se puede extender facilmente el gráfo mostrado en \ref{fig:grafo-computacional} para modelar a un perceptrón de $n$ capas.
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=10cm]{capitulo2/images/grafo}
		\caption{Ejemplo de un perceptrón de una sola capa representado mediante un gráfo computacional, siendo $x$ la entrada, $w^{1}$ la matriz de pesos, $b^{1}$ la matriz de bias, $u^{(1)}$ y $u^{(2)}$ nodos intermedios en el gráfo y $y^{1}$ la salida de la red. La ecuación modelada es $y ^ {1} = f(W^{1}x + b ^ {1})$.}
		\label{fig:grafo-computacional}
	\end{figure}

	%\subsection{Algoritmos de aprendizaje}


	\subsection{Batch Normalization}

	Cada capa de una red neuronal tiene entradas con su correspondiente distribución la cual es afectada durante el entrenamiento por la aleatoriedad en la inicialización de parámetros y en la aleatoriedad de los datos de entrada. Los efectos de esta aleatoriedad en la distribución de las entradas de la red hacia las capas internas en el momento de entrenamiento es descrita como un cambio en la covarianza, el cual provoca inestabilidad en la red.
	
	La técnica de \textit{Batch Normalization} es utilizada para incrementar la estabilidad, la velocidad y el desempeño de una red neuronal. Esta técnica fue introducida en el 2005 por \cite{batch-normalization}.

	En una red neuronal, la técnica de Batch Normalization consiste en una etapa de normalización de las medias y varianzas de las entradas de una capa de la red. Esta operación esta definida de la siguiente manera:

	\begin{equation}
		\mu_{B} = \frac{1}{m} \sum_{i=1}^{m} x_{i} 
	\end{equation}

	\begin{equation}
		\sigma_{B}^{2} = \frac{1}{m} \sum_{i=1}^{m} (x_{i} - \mu_{B})^{2}
	\end{equation}

	done $B$ denota algún mini batch de tamaño $m$. Para una capa con una entrada $x \in \mathbb{R}^{n}$ entonces:

	\begin{equation}
		\hat{x}^{(k)}_{i} = \frac{x^{(k)}_{i} - \mu_{B}^{(k)}}{\sqrt{\sigma_{B}^{(k)^{2}} + \epsilon}}
	\end{equation}

	done $k \in [1, n]$, $i \in [1, m]$, $\mu_{B}^{(k)}$ y $\sigma_{B}^{(k)^{2}}$ son la media y varianza por cada dimensión respectivamente; $\epsilon$ es añadido como una constante arbitraria y pequeña para asegurar la estabilidad numérica del denominador.

	Finalmente, la salida de la capa es:

	\begin{equation}
		y^{(k)}_{i} = \gamma^{(k)} \hat{x}^{(k)}_{i} + \beta^{(k)}
	\end{equation}
    
	de donde los parámetros $\gamma^{(k)}$ y $\beta^{(k)}$ serán aprendidos durante el entrenamiento.

    \subsection{Redes Neuronales Convolucionales}
    
    Las redes neuronales convolucionales también llamadas convolutivas (CNN), son una arquitectura especial de redes neuronales que permite el procesamiento de datos que tengan una estructura de grilla. Algunos ejemplos de esta estructura son: una serie de tiempo es una grilla 1D o una imágene, la cual puede ser vista como una grilla 2D de pixeles. Se puede decir, que una red convolutiva no es más que una red neuronal que utiliza la operación de convolución en lugar de una multiplicación tensorial normal \cite{deeplearningbook}. \\
    
    La operación de convolución esta definida de la siguiente manera:
    
	\begin{equation}
		y(t) = x(t) * w(t)
	\end{equation}

    \begin{equation}
    	y(t) = \int_{-\infty}^{\infty} x(\tau)w(t-\tau)d\tau
    \end{equation}
    
    En terminolgía de las CNN $x$ es la entrada a la red, $w$ es llamado el \textbf{kernel} o \textbf{filtro} y $y$ el mapa de características. \\
    
    Propiamente en los sitemas computacionales no se pueden tener funciones continuas, estas tienen que ser discretas, por lo tanto la operación de convolución que una CNN utiliza es:
    
    \begin{equation}
    	y(t) = \sum_{\tau = -\infty}^{\infty} x(\tau)w(t-\tau)
    \end{equation}
    
    Naturalmente, si lo que se esta trabajando es una imagen, tenemos que aplicar la operación de convolución en dos ejes, es decir:
    
    \begin{equation}
    	y(i,j) = \sum_{m}\sum_{n} x(i,j)w(i-m, j-n)
    \end{equation}

	Si se toma el gráfo computacional del ejemplo de la Figura \ref{fig:grafo-computacional} el cual modela a un perceptrón de una sola capa y se cambia su operación de multiplicación matricial por la operación de convolución, tenemos una capa convolucional:

	\begin{equation}
		y ^ {1} = f(W ^ {1} * x + b ^ {1}) 
	\end{equation}

	La manera en la que se entrenan estas variantes de MLP es con el mismo algoritmo de optimización que un perceptrón.
    
    En la Figura \ref{fig:CNNFilter} se puede ver un ejemplo de cómo una imagen es procesada por la etapa de convolución en una CNN.
    
    \begin{figure}[H]
    	\centering
    	\includegraphics[width=0.7\textwidth]{capitulo2/images/CNN_window.png}
    	\caption{Matriz de pesos conocida como kernel o filtro aplicada a una imagen.}
    	\label{fig:CNNFilter}
    \end{figure}
    
    \subsubsection{Pooling}
    Es una de las operaciones adicionales que se implementan en las CNN. En general se puede establecer que una típica capa convolucional tiene tres partes:
    
    \begin{enumerate}
    	\item Operación de convolución: Es donde utiliza una entrada y la convoluciona con un filtro $w$.
    	\item Función de activación: A veces es llamada fase de detección. Consiste en aplicar una función $f$ al resultado de la primera etapa para modificar la salida y volverla no lineal.
    	\item Etapa de Pooling: Es una manera de modificar aún más la salida de modo que se incremente la significancia estadística de los datos extraidos.
    \end{enumerate}

	La operación de pooling permite que la red sea tolerante a traslaciones y rotaciones leves de la imagen. Por ejemplo, se puede aplicar la función \textit{max pooling} a cada uno de los valores de $f(W*h)$ para obtener una generalización de los datos más importantes observados por la etapa de detección. \\
	
	Una manera efectiva de reducir el tamaño de los datos que la red tiene que procesar a través de sus capas, es utilizar la operación pooling para remuestrear. Esto se logra definiendo una ventana a la que la que se le aplicará la operación. Esta técnica también permite que algunas CNN puedan procesar imágenes de longitud variable.

	Existen diversas operaciones de pooling, las más comúnes son \textit{Max Pooling} y \textit{Average Pooling}. En la Figura \ref{fig:max-pooling} se puede apreciar una representación gráfica de la operación de Max Pooling sobre alguna matríz.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{capitulo2/images/max_pooling}
		\caption{Representación gráfica de la operación Max Pooling.}
		\label{fig:max-pooling}
	\end{figure}
    
   	
\subsection{Redes Neuronales Recurrentes}

Las redes neuronales recurrentes (RNNs) son una familia de redes neuronales especializadas en procesar secuencias de datos. Es decir, pueden procesar entradas de la forma: $x^{(1)}, x^{(2)}, \dots, x^{(t)}$. Esta particular arquietectura, permite modelar secuencias de datos de longitud variable que serían imprácticas para cualquier otra arquitectura. \\

Las RNNs modelan sistemas dinámicos, es decir, que cada instante $t$ tenemos un sistema $s(t)$ con un estado diferente. Para que los siguientes estados del sistema tengan información de los estados pasados, las RNNs tienen al menos una conexión que es recurrente, es decir, que depende de un estado anterior o en algunos casos de estados futuros. \\

Una de sus principales ventajas es la compartición de parámetros. Esto quiere decir que para diferentes estados del sistema, podemos aplicar los mismos parámetros $\theta$, permitiendo así, entrenar solo un conjunto de parámetros para todo el sistema en vez de un conjunto particular para cada estado. \\

En la Figura \ref{fig:rnn} se puede apreciar un ejemplo de una RNN que cuya ecuación es: $s(t) = f(s^{(t-1)}, \theta)$. Como se han definido las redes neuronales en términos de gráfos, es posible utilizar el algoritmo de back-propagation para calcular los gradientes de cada estado. Normalmente cuando se aplica back-propagation a una RNN se le conoce como back-propagation through time (BPTT). \\

\begin{figure}[H]
	\centering
	\includegraphics[width=4cm, height=5.5cm]{capitulo2/images/rnn}
	\caption{Ejemplo de una RNN que modela la ecuación $s(t) = f(s^{(t-1)}, \theta)$, donde $\theta$ representa los parámetros $W$ y $V$, $f$ la función no lineal aplicada a $Wx^{(t)}$ y $V$ la matriz de pesos aplicada a $s^{(t-1)}$.}
	\label{fig:rnn}
\end{figure}

La manera que tiene una RNN para poder procesar una secuencia de longitud variable y brindar información respecto de ella, es a través de los estados $s(t)$ ya que estos si tienen una longitud fija. De este modo se puede decir que funcionan muy parecido a una CNN, ya que sumarizan las características de la secuencia hasta el momento $t$. Para realizar alguna predicción final, normalmente se utiliza algúna otra capa que efectue una función $f$, justo como lo hacen las CNNs. \\
  
    \subsubsection{Arquitectura Encoder-Decoder}
    Esta arquitectura de RNN se ha vuelto muy popular pues permite a una red procesar secuencias de longitud variable y obtener como resultado secuencias de longitud variable. Este tipo de problemas son conocidos como problemas sequence-to-sequence. Algunos ejemplos de problemas de este estilo son el reconocimiento del habla en tiempo real o el reconocimiento de la escritura. \\
    
    La arquitectura se compone de dos redes recurrentes, la primera es denominada el \textit{encoder}, el cual es una red que 'codifica' la entrada $x^{(t)}$. Si lo que se quiere es codificar una serie de tiempo, normalmente se usará una RNN y como salida será la señal $s(t)$. En este tipo de redes a la señal $s(t)$ se le conoce como el contexto $C$. \\
    
    La segunda red que compone a la arquitectura es el \textit{decoder}, el cual toma como entrada el contexto $C$ generado previamente por el encoder y lo utiliza para generar la secuencia de salida. El decoder es en general una RNN.
    
    \subsubsection{Long Short-Term Memory}
   	Hasta ahora, las arquitecturas más exitosas para procesar secuencias son las llamadas Gated RNN. Estas redes permiten aprender secuencias muy largas o que requieran memorizar mucha información. El problema que existía, era que el gradiente tendía desaparecer conforme la red se volviera más y más profunda. Las Gated RNN son la solución más exitosa a este problema. \\
   	
   	La Gated RNN más popular es la Long Short-Term Memory (LSTM). La idea de esta red, es crear ciclos entre los mismos nodos pero que esten condicionados con el contexto, de modo que la red pueda decidir cuando olvidar la información previa. \\
   	
   	La LSTM es puede verse como una compuerta lógica que puede ser implementada en otra RNN para crear una arquitectura más robusta. En la Figura \ref{fig:lstm} se muestra un ejemplo de la compuerta LSTM. La LSTM implementa diferentes puertas las cuales son: \textbf{input gate} $g^{(t)}$, \textbf{forget gate} $f^{(t)}$ y la \textbf{output gate} $q^{(t)}$. Todas estas puertas ayudan a la LSTM a controlar en que momento es oportuno olvidar la información previamente encontrada en los anteriores estados. \\
   	
   	\begin{figure}
   		\centering
   		\includegraphics[width=\textwidth]{capitulo2/images/lstm}
   		\caption{Una compuerta LSTM típica.}
   		\label{fig:lstm}
	   \end{figure}
	   
	Las ecuaciones que describen a una LSTM típicamente son:  

	\begin{equation}
		f_{i}^{(t)} = \sigma \left( b_{i}^{f} + \sum_{j} U_{i,j}^{f} x_{j}^{(t)} + \sum_{j} W_{i,j}^{f} h_{j}^{t-1} \right)
	\end{equation}

	\begin{equation}
		s_{i}^{(t)} = f_{i}^{(t)} s_{i}^{t-1} + g_{i}^{(t)} \sigma \left( b_{i} + \sum_{j} U_{i,j} x_{j}^{(t)} + \sum_{j} W_{i,j} h_{j}^{t-1} \right)
	\end{equation}

	\begin{equation}
		g_{i}^{(t)} = \sigma \left( b_{i}^{g} + \sum_{j} U_{i,j}^{g} x_{j}^{(t)} + \sum_{j} W_{i,j}^{g} h_{j}^{t-1} \right)
	\end{equation}

	\begin{equation}
		h_{i}^{(t)} = tanh \left( s_{i}^{(t)} \right) q_{i}^{(t)}
	\end{equation}

	\begin{equation}
		q_{i}^{(t)} = = \sigma \left( b_{i}^{o} + \sum_{j} U_{i,j}^{o} x_{j}^{(t)} + \sum_{j} W_{i,j}^{o} h_{j}^{t-1} \right)
	\end{equation}

	de donde $s^{(t)}$ es el estado interno de la RNN, los parámtreos $b, W, U$ son transformaciones lineales que serán aprendidas, $x^{(t)}$ son las entradas a la red.

	\subsubsection{Modelos de Lenguaje Condicional}

	Un modelo de lenguaje define la distribución de probabilidad sobre una serie de tokens en un lenguaje natural. Dependiendo de como el modelo es diseñado, un token puede representar una letra, una palabra o incluso un solo bit. Cuando se utilizan modelos de deep learning para resolver este problema, usualmente este modelo es llamado modelo de lenguaje neural.

	Los modelos de lenguaje neurales tienen ventajas tales como:
	\begin{itemize}
		\item Resuelven el problema de dimensionalidad presentado por otros modelos.
		\item Son capaces de reconocer la similitud entre dos palabras sin perder la generalidad de codificarlas de una forma distinta.
		\item Alcanzan una buena comprensión estadística entre una palabra y su contexto.
	\end{itemize}

	En estos modelos, las palabras tienden a ser representadas por un identificador, el cual usualmente es un número, no obstante, una práctica muy común y que ha demostrado ser muy útil son los \textit{word embeddings}. Estos concisten en codificar las palabras no a través de un solo número, sino a través de un conjunto de números decimales.

	Un modelo de lenguaje condicional, es entonce, un modelo de lenguaje que toma en cuenta las palabras que han sido generadas previamente. Es decir:

	\begin{equation}
		P(w_{1}, \dots, w_{m}) = \prod_{i = 1}^{m} P(w_{i}|w_{1}, \dots, w_{i-1})
	\end{equation}

	\subsubsection{Sistema de Atención}

	El sistema de atención fue introducido por \cite{bahdanau2014neural} y es en escencia un promedio con pesos. El resultado de un sistema de atención es un vector de contexto $c_{t}$ el cual es obtenido al realizar el promedio entre las anotaciones $a_{t}$ y multiplicarlas por unos pesos $\alpha_{t}$, los cuales usualemente estan en el rango $[0,1]$. El modelo de atención es capaz de aprender en que parte del texto enfocarse en cada instante de tiempo $t$ por lo que ha supuesto un impresionante avance en los modelos de lenguaje natural.

	\subsubsection{Positional Embeddings}

	Debido a que en un modelo de lenguaje una palabra puede representar cosas diferentes dependiendo de la posición que ocupe en la secuencia, es en ocasiones necesario brindar a la red de más información sobre la ubicación de cada token. Los \textit{Positional Embeddings} fueron originalmente propuestos por \cite{attentionisallyouneed}. La técnica conciste en sumar un vector $pe$ a los \textit{words embeddings} de cada token. Los autores del artículo proponen al vector $pe$ de tal forma que: 

	\begin{equation}
		pe_{t}^{(i)} = f(t)^{(i)} = \left\{
			\begin{array}{ll}
				sin(\omega_{k}t), & \mbox{si } i = 2k \\
				cos(\omega_{k}t), & \mbox{si } i = 2k + 1
			\end{array}
		\right.
	\end{equation}

	con

	\begin{equation}
		\omega_{k} = \frac{1}{10000^{2k/d}}
	\end{equation}

	donde $d$ es la dimensión de los \textit{word embeddings}.

\subsection{Aprendizaje profundo como servicio}
El entrenamiento de redes neuronales profundas, conocidas como aprendizaje profundo es en la actualidad áltamente complejo computacionalmente. Requiere un sistema con la combinación correcta de software, drivers, memoria, red y recursos de almacenamiento, por factores como estos los proveedores de cloud computing como Amazon Web Services, Microsoft Azure o Google Cloud ofrecen actualmente servicios de Machine Learning proveyendo API's como pueden ser de entrenamiento de modelos o de visualización de datos y generación de estadísticas, permitiendo que desarrolladores y científicos de datos se enfoquen mas en tareas como el entrenamiento de modelos, análisis de datos, etc.
\\\\
Los modelos de aprendizaje profundo requieren de un proceso experimental e iterativo, requiriendo cientos e incluso miles de ejecuciones que requieren de un amplio poder de cómputo para encontrar la combinación correcta de las configuraciones e hiper-parámetros de la red neuronal. Esto puede tomar semanas o incluso meses y este tipo de servicios garantiza una disponibilidad en todo momento y en conjunto permite que un sistema completo esté dividido en módulos consiguiendo que el mantenimiento y detección de fallos sean tareas más sencillas.
\\\\ 
En la figura \ref{fig:DLAAS} se puede observar la arquitectura de un sistema divido en módulos y que hace uso de herramientas de Machine Learning para dar respuesta a otros módulos del sistema.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{capitulo2/images/DLAAS.png}
	\caption{Ejemplo de sistema con módulo de Machine Learning}
	\label{fig:DLAAS}
\end{figure}

%==============================================================

\section{Métodos de reconocimiento de expresiones matemáticas}
\subsection{Análisis sintáctico dirigido}
Los lenguajes libres de contexto, son aquellos que tienen una notación recursiva natural llamada \textit{gramática libre de contexto}. Por ende, un lenguaje libre de contexto es todo aquel que puede ser representado por una gramática libre de contexto.

Una gramática libre de contexto G, queda definida de la siguiente manera:

\begin{equation}
G = (V, T, P, S)
\end{equation}

de donde, V es el conjunto de variables, T el conjunto de símbolos terminales, P el conjunto de producciones y S el punto de inicio \cite{automata}.

El lenguaje matemático, es decir, las expresiones matemáticas son un lenguaje libre de contexto. Esto quiere decir que es posible definir una gramática libre de contexto para definir a las expresiones matemáticas. Esta es una práctica muy común en la teoría de compiladores.

Sabiendo esto, una aproximación a la resolución del problema de reconocer expresiones matemáticas en imágenes es la que describe \cite{gramaticasAnderson}. El método consiste en dos etapas:

\begin{itemize}
	\item Reconocimiento de caracteres: Utilizar algún método de reconocimiento de patrones para localizar los caracteres y anotar sus coordenadas. 
	\item Análisis sintáctico dirigido: Utilizar la etapa previa para determinar la jerarquía, basándose en un conjunto de reglas definidas (las gramáticas libres de contexto).
\end{itemize}

En la Figura \ref{fig:gramaticas}, se puede ver un ejemplo del proceso de reconocimiento propuesto por este método.

\begin{figure}[h]
	\centering
	\subfigure[]{\includegraphics[width=6cm]{capitulo2/images/gramaticas1}}
	\subfigure[]{\includegraphics[width=6cm]{capitulo2/images/gramaticas2}}
	\caption{\textbf{a)} La primera etapa del método de reconocimiento, se anotan las coordenadas de de cada caracter. \textbf{b)} Se realiza un análisis sintáctico con las gramáticas libres de contexto definidas.}
	\label{fig:gramaticas}
\end{figure}

\subsection{Análisis estructural}

Este método coincide con el primero en que debe de utilizar una técnica de reconocimiento de patrones para etiquetar primero los símbolos. Las etiquetas que utiliza tienen que ver son su posición en la imagen, así como su tamaño. 

La diferencia en este método, radica en su segunda etapa. No se realizará un análisis con gramáticas, en su lugar se intentara deducir la estructura jerárquica con algún otro método. El artículo \cite{spanningtree} propone utilizar el algoritmo de Kruskal para obtener un árbol de recubrimiento mínimo por niveles, de este modo se puede saber la estructura de la expresión matemática recorriendo el gráfo resultante.La Figura \ref{fig:spanningtree} muestra un ejemplo de como funciona este método.

\begin{figure}[h]
	\centering
	\includegraphics[width=8cm]{capitulo2/images/spanningtree}
	\caption{Utilización de un árbol de recubrimiento mínimo para el reconocimiento de expresiones matemáticas.}
	\label{fig:spanningtree}
\end{figure}


\subsection{Image Captioning}

Es una rama emergente del \textit{deep learning} que ha ido ganando atención en los últimos años. Este campo es un punto intermedio entre la vision por computadora y el procesamiento del lenguaje natural. El actual estado del arte en image captioning tiene una aproximación similar a los modelos sequence-to-sequence, los cuales utilizan una arquitecura Encoder-Decoder \cite{imagetolatex}.

Si se trata al problema de reconocer expresiones matemáticas en imagenes como un problema sequence-to-sequence de image captioning, se puede emplear una arquitectura de Encoding-Decoding para hacer la conversión de la imagen a LaTeX de manera directa. Esto permite a la red manejar imagenes de longitud variable y reconocer los símbolos a la vez que va reconociendo las expresiones.

La arquitectura que se está utilizando actualmente para solucionar este problema se muestra en la Figura \ref{fig:imgcaptioning} \cite{imagetolatex}\cite{imagemarkup}\cite{chino}.

\begin{figure}
	\centering
	\includegraphics[width=8cm]{capitulo2/images/imgcaptioning}
	\caption{Arquitectura de image captioning para reconocer expresiones matemáticas en imagenes.}
	\label{fig:imgcaptioning}
\end{figure}

%==============================================================

\section{Aplicación web}
En la ingeniería de software se denomina aplicación web a aquellas herramientas que los usuarios pueden utilizar accediendo a un servidor web a través de internet o de una intranet mediante un navegador. En otras palabras, es un programa que se codifica en un lenguaje interpretable por los navegadores web en la que se confía la ejecución al navegador \cite{appweb}.

\subsection{Django}
Django es un framework de desarrollo web completamente desarrollado en Python. Permite de una manera rápida poder implementar una aplicación web en el lenguaje Python. Las siguientes, son de las principales características de Django:

\begin{itemize}
    \item \textbf{Rápido}: Tiene como filosofía ayudar a los desarrolladores a crear aplicaciones en el menor tiempo posible.
    \item \textbf{Completo}: Incluye cientos de librerías que permiten ahorrar tiempo y automatizar tareas.
    \item \textbf{Seguro}: Es una de las principales características de Django ya que incluye soluciones a los principales ataques que puede sufrir una aplicación web.
    \item \textbf{Escalable}: Con el patrón de diseño de Django es posible incrementar o decrementar la capacidad de un sitio.
    \item \textbf{Versátil}: Es utilizado por muchas empresas y organizaciones a lo largo del mundo para crear diferentes tipos de proyectos.
\end{itemize}

\subsubsection{Modelo-Vista-Template}
El Modelo-Vista-Template (MTV) es el patrón de diseño que Django implementa. Este patrón es una modificación al conocido Modelo-Vista-Controlador (MVC). La diferencia radica en que Django se encarga de hacer la parte del controlador, por ende el desarrollador solamente tiene que preocuparse por implementar la lógica de negocio y de como mostrará los datos. En la Figura \ref{fig:mtv}, se puede ver una representación del patrón MTV. En el patrón de diseño MTV \cite{mtv}:

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{capitulo2/images/mtv.png}
    \caption{Representación del patrón de diseño Modelo-Vista-Template.}
    \label{fig:mtv}
\end{figure}

\begin{itemize}
    \item \textbf{Modelo}: La capa de acceso a la base de datos. Esta capa contiene toda la información sobre los datos: cómo acceder a estos, cómo validarlos, cuál es el comportamiento que tiene, y las relaciones entre los datos.
    \item \textbf{Template}: La capa de presentación. Esta capa contiene las decisiones relacionadas a la presentación: como algunas cosas son mostradas sobre una página web o otro tipo de documento.
    \item \textbf{Vista}: La capa de la lógica de negocios. Esta capa contiene la lógica que accede al modelo y la delega a la plantilla apropiada: puedes pensar en esto como un puente entre el modelos y las plantillas.
\end{itemize}

\subsection{API REST}
\subsubsection{Application Programming Interface}
Una Interfaz de Programación de Aplicaciones o API es un conjunto de definiciones y protocolos que se utilizan para desarrollar e integrar el software de las aplicaciones.

Las API permiten que sus servicios se comuniquen con otros, sin necesidad de saber como están implementados. Esto simplifica el desarrollo de las aplicaciones y permite ahorrar tiempo y dinero \cite{apiArticle}.
\subsubsection{Represenational State Transfer}

Representational State Transfer (REST) es un estilo de arquitectura basado en un conjunto de principios que describen como recursos interconectados son definidos y direccionados. Estos principios fueron descritos en el año 2000 por Roy Fielding como parte de obtención de su doctorado.
\\
Es importante hacer énfasis en que REST es un \textbf{estilo de software de arquitectura} y no un conjunto de estandares. Como resultado, dichas aplicaciones o arquitecturas son en ocasiones referidas como aplicaciones RESTful o REST-style \cite{restArticle}. 
\\
Una aplicación o arquitectura considerada RESTful o REST-style es caracterizada por:
\begin{itemize}
	\item La funcionalidad y estado son dividiad en recursos distribuidos.
	\item Cada recurso es únicamente direccionable usando un conjunto uniforme y mínimo de comandos (típicamente usando comandos HTTP de GET, POST, PUT o DELETE).
	\item El protocolo es cliente/servidor, stateless, por capas y soporta almacenamiento cache.
\end{itemize} 
 La figura \ref{fig:rest_mess} ilustra el uso de REST para servicios Web.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{capitulo2/images/rest_messages.jpg}
	\caption{Consumidor y proveedor de servicios comunicandose mediante solicitudes y respuestas REST.}
	\label{fig:rest_mess}
\end{figure}  
\subsubsection{Autentificación}
Para hablar de autentificación es necesario primero entender la diferencia entre identificación y autentificación, por un lado la identificación es la capacidad de identificar de forma exclusiva a un usuario de un sistema o una aplicación que se está ejecutando, mientras que la autentificación es la capacidad de demostrar que un usuario o una aplicación es quien dicha persona o aplicación asegura ser \cite{authent}.\\\\
Para el caso de una REST API es en muchas ocasiones necesario que se lleve a cabo la autentificación para permitir o denegar el acceso a recursos de un servidor por ejemplo de acuerdo a los permisos concedidos en función de las credenciales de autentificación para así asegurar que los datos sean visibles únicamente a aquellos que proporcionen las credenciales adecuadas y dispongan de los permisos necesarios.

%https://www.ibm.com/support/knowledgecenter/es/SSFKSJ_7.5.0/com.ibm.mq.sec.doc/q009740_.htm
\input{capitulo2/android/principal.tex}


%\section{Estado del arte}
%
%%ESTADO DEL ARTE
%Algunos sistemas similares que se han desarrollado son:
%\begin{itemize}
%	\item Mathphix \cite{mathphix}%
%	\item MyScript Nebo \cite{nebo}%[Cita].
%	\item SESHAT \cite{AlvaroPR16}%[4].
%	\item IDEAL Math Writer \cite{idmath} %[5].
%\end{itemize}
%Los cuales se describen en la tabla \ref{tab:state_of_art}: \\\\
%\begin{longtabu} to 1\textwidth { | X[m,c] | X[m,c] | X[m,c] | }
%	\hline
%	\textbf{SOFTWARE} & \textbf{CARACTERISTICAS} & \textbf{PRECIO EN EL MERCADO} \\
%	\hline
%	Mathpix  & Es una aplicación de escritorio en la que puedes usar un comando para tomar una captura de pantalla y convertir el texto capturado a LaTeX. También cuenta con un API de pago  & Este producto cuenta con diferentes planes de pago según su uso o el tiempo que decidas pagarlo. Tiene distinto trato para empresas. Un ejemplo de suscripción mensual es \$99 dólares el mes.  \\
%	\hline
%	MyScript Nebo  & Es una aplicación Android que transforma el texto escrito en el dispositivo en texto digital. Incluye soporte para ecuaciones. Es necesario el uso de una pluma digital.& \$189.00 en Google Play Store  \\
%	\hline
%	Mathpix  & Es una aplicación de escritorio en la que puedes usar un comando para tomar una captura de pantalla y convertir el texto capturado a LaTeX. También cuenta con un API de pago  & Este producto cuenta con diferentes planes de pago según su uso o el tiempo que decidas pagarlo. Tiene distinto trato para empresas. Un ejemplo de suscripción mensual es \$99 dólares el mes.  \\
%	\hline
%	SESHAT  & Es un proyecto de doctorado de la Universidad Politécnica de Valencia open source. Convierte el texto de imágenes en texto digital y en formato LaTeX. Soporta ecuaciones. Necesita ser instalado mediante terminal en Linux. & No es una aplicación comercial  \\
%	\hline
%	\caption{Resumen de productos similares}
%	\label{tab:state_of_art}
%\end{longtabu}
%
